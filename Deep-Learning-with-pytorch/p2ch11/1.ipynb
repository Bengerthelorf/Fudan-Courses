{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.util import enumerateWithEstimate\n",
    "from util.logconf import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "# log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsets import LunaDataset\n",
    "from model import LunaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaPrepCacheApp:\n",
    "    @classmethod\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=1024,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=8,\n",
    "            type=int,\n",
    "        )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        self.prep_dl = DataLoader(\n",
    "            LunaDataset(\n",
    "                sortby_str='series_uid',\n",
    "            ),\n",
    "            batch_size=self.cli_args.batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            self.prep_dl,\n",
    "            \"Stuffing cache\",\n",
    "            start_ndx=self.prep_dl.num_workers,\n",
    "        )\n",
    "        for _ in batch_iter:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1024\n",
    "batch_size = 128\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:12,538 INFO     pid:1350 dsets:182:__init__ <dsets.LunaDataset object at 0x7f53050df210>: 551065 training samples\n"
     ]
    }
   ],
   "source": [
    "prep_dl = DataLoader(\n",
    "    LunaDataset(\n",
    "        sortby_str='series_uid',\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:35,048 WARNING  pid:1350 util.util:219:enumerateWithEstimate Stuffing cache ----/4306, starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:35.048581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:35,779 INFO     pid:1350 util.util:236:enumerateWithEstimate Stuffing cache    4/4306, done at 2024-02-07 22:48:03, 0:10:28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m      5\u001b[0m batch_iter \u001b[38;5;241m=\u001b[39m enumerateWithEstimate(\n\u001b[1;32m      6\u001b[0m     prep_dl,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStuffing cache\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     start_ndx\u001b[38;5;241m=\u001b[39mprep_dl\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/Fudan-Courses/Deep-Learning-with-pytorch/p2ch11/util/util.py:224\u001b[0m, in \u001b[0;36menumerateWithEstimate\u001b[0;34m(iter, desc_str, start_ndx, print_ndx, backoff, iter_len)\u001b[0m\n\u001b[1;32m    219\u001b[0m log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ----/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, starting\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m     desc_str,\n\u001b[1;32m    221\u001b[0m     iter_len,\n\u001b[1;32m    222\u001b[0m ))\n\u001b[1;32m    223\u001b[0m start_ts \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 224\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_ndx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_ndx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcurrent_ndx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_ndx\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ... <1>\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Fudan-Courses/Deep-Learning-with-pytorch/p2ch11/dsets.py:195\u001b[0m, in \u001b[0;36mLunaDataset.__getitem__\u001b[0;34m(self, ndx)\u001b[0m\n\u001b[1;32m    192\u001b[0m candidateInfo_tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidateInfo_list[ndx]\n\u001b[1;32m    193\u001b[0m width_irc \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m)\n\u001b[0;32m--> 195\u001b[0m candidate_a, center_irc \u001b[38;5;241m=\u001b[39m \u001b[43mgetCtRawCandidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidateInfo_tup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries_uid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidateInfo_tup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter_xyz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth_irc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m candidate_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(candidate_a)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    201\u001b[0m candidate_t \u001b[38;5;241m=\u001b[39m candidate_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mytorch/lib/python3.11/site-packages/diskcache/core.py:1872\u001b[0m, in \u001b[0;36mCache.memoize.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for callable to cache arguments and return values.\"\"\"\u001b[39;00m\n\u001b[1;32m   1871\u001b[0m key \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39m__cache_key__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1872\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mENOVAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m ENOVAL:\n\u001b[1;32m   1875\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mytorch/lib/python3.11/site-packages/diskcache/fanout.py:285\u001b[0m, in \u001b[0;36mFanoutCache.get\u001b[0;34m(self, key, default, read, expire_time, tag, retry)\u001b[0m\n\u001b[1;32m    283\u001b[0m shard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shards[index]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpire_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Timeout, sqlite3\u001b[38;5;241m.\u001b[39mOperationalError):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m~/anaconda3/envs/mytorch/lib/python3.11/site-packages/diskcache/core.py:1173\u001b[0m, in \u001b[0;36mCache.get\u001b[0;34m(self, key, default, read, expire_time, tag, retry)\u001b[0m\n\u001b[1;32m   1170\u001b[0m ((rowid, db_expire_time, db_tag, mode, filename, db_value),) \u001b[38;5;241m=\u001b[39m rows\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;66;03m# Key was deleted before we could retrieve result.\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m~/Fudan-Courses/Deep-Learning-with-pytorch/p2ch11/util/disk.py:79\u001b[0m, in \u001b[0;36mGzipDisk.fetch\u001b[0;34m(self, mode, filename, value, read)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode, filename, value, read):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Override from base class diskcache.Disk.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    :return: corresponding Python value\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGzipDisk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m MODE_BINARY:\n\u001b[1;32m     82\u001b[0m         str_io \u001b[38;5;241m=\u001b[39m BytesIO(value) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mytorch/lib/python3.11/site-packages/diskcache/core.py:282\u001b[0m, in \u001b[0;36mDisk.fetch\u001b[0;34m(self, mode, filename, value, read)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(op\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory, filename), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(reader)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(io\u001b[38;5;241m.\u001b[39mBytesIO(value))\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, index, row, col)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "batch_iter = enumerateWithEstimate(\n",
    "    prep_dl,\n",
    "    \"Stuffing cache\",\n",
    "    start_ndx=prep_dl.num_workers,\n",
    ")\n",
    "for _ in batch_iter:\n",
    "    pass\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=0\n",
    "batch_size=32 # 感觉要降 lol\n",
    "epochs=1\n",
    "tb_prefix='p2ch11'\n",
    "comment='dlwpt'\n",
    "\n",
    "time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')\n",
    "\n",
    "trn_writer = None\n",
    "val_writer = None\n",
    "totalTrainingSamples_count = 0\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:44,571 INFO     pid:1350 __main__:004:initModel Using CUDA; 1 devices.\n"
     ]
    }
   ],
   "source": [
    "def initModel():\n",
    "    model = LunaModel()\n",
    "    if use_cuda:\n",
    "        log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    return model\n",
    "\n",
    "model = initModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOptimizer():\n",
    "    return SGD(model.parameters(), lr=0.001, momentum=0.99)\n",
    "\n",
    "optimizer = initOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:37:48,585 INFO     pid:1350 dsets:182:__init__ <dsets.LunaDataset object at 0x7f52fa247fd0>: 495958 training samples\n"
     ]
    }
   ],
   "source": [
    "def initTrainDl(batch_size):\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "    )\n",
    "\n",
    "    batch_size = batch_size\n",
    "    if use_cuda:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_cuda,\n",
    "    )\n",
    "\n",
    "    return train_dl\n",
    "\n",
    "train_dl = initTrainDl(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     11\u001b[0m     val_dl \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     12\u001b[0m         val_ds,\n\u001b[1;32m     13\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     14\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[1;32m     15\u001b[0m         pin_memory\u001b[38;5;241m=\u001b[39muse_cuda,\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_dl\n\u001b[0;32m---> 20\u001b[0m val_dl \u001b[38;5;241m=\u001b[39m initValDl(\u001b[43mbatch_size\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "def initValDl(batch_size):\n",
    "    val_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=True,\n",
    "    )\n",
    "\n",
    "    batch_size = batch_size\n",
    "    if use_cuda:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_cuda,\n",
    "    )\n",
    "\n",
    "    return val_dl\n",
    "\n",
    "val_dl = initValDl(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# Used for computeBatchLoss and logMetrics to index into metrics_t/metrics_a\n",
    "METRICS_LABEL_NDX=0\n",
    "METRICS_PRED_NDX=1\n",
    "METRICS_LOSS_NDX=2\n",
    "METRICS_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(device, non_blocking=True)\n",
    "    label_g = label_t.to(device, non_blocking=True)\n",
    "\n",
    "    logits_g, probability_g = model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='none')\n",
    "    loss_g = loss_func(\n",
    "        logits_g,\n",
    "        label_g[:,1],\n",
    "    )\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = \\\n",
    "        label_g[:,1].detach()\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = \\\n",
    "        probability_g[:,1].detach()\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = \\\n",
    "        loss_g.detach()\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTraining(epoch_ndx, train_dl, totalTrainingSamples_count=0):\n",
    "    model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_var = computeBatchLoss(\n",
    "            batch_ndx,\n",
    "            batch_tup,\n",
    "            train_dl.batch_size,\n",
    "            trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # This is for adding the model graph to TensorBoard.\n",
    "        # if epoch_ndx == 1 and batch_ndx == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         model = LunaModel()\n",
    "        #         self.trn_writer.add_graph(model, batch_tup[0], verbose=True)\n",
    "        #         self.trn_writer.close()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "    return trnMetrics_g.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            computeBatchLoss(\n",
    "                batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 17:44:38,202 INFO     pid:20110 __main__:005:<module> Epoch 1 of 1, 15499/1723 batches of size 32*1\n",
      "2024-02-07 17:44:38,216 WARNING  pid:20110 util.util:219:enumerateWithEstimate E1 Training ----/15499, starting\n",
      "2024-02-07 17:44:50,932 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training    4/15499, done at 2024-02-08 04:41:28, 10:56:49\n",
      "2024-02-07 17:44:53,027 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training   16/15499, done at 2024-02-07 21:29:39, 3:45:01\n",
      "2024-02-07 17:45:01,473 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training   64/15499, done at 2024-02-07 19:17:03, 1:32:25\n",
      "2024-02-07 17:45:25,039 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training  256/15499, done at 2024-02-07 18:31:41, 0:47:03\n",
      "2024-02-07 17:47:01,638 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training 1024/15499, done at 2024-02-07 18:20:46, 0:36:08\n",
      "2024-02-07 17:53:30,034 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Training 4096/15499, done at 2024-02-07 18:18:10, 0:33:31\n",
      "2024-02-07 18:17:31,851 WARNING  pid:20110 util.util:249:enumerateWithEstimate E1 Training ----/15499, done at 2024-02-07 18:17:31\n",
      "2024-02-07 18:17:32,469 WARNING  pid:20110 util.util:219:enumerateWithEstimate E1 Validation  ----/1723, starting\n",
      "2024-02-07 18:17:32,816 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Validation     4/1723, done at 2024-02-07 18:19:31, 0:01:58\n",
      "2024-02-07 18:17:33,459 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Validation    16/1723, done at 2024-02-07 18:19:12, 0:01:40\n",
      "2024-02-07 18:17:35,978 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Validation    64/1723, done at 2024-02-07 18:19:05, 0:01:33\n",
      "2024-02-07 18:17:45,991 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Validation   256/1723, done at 2024-02-07 18:19:03, 0:01:30\n",
      "2024-02-07 18:18:25,745 INFO     pid:20110 util.util:236:enumerateWithEstimate E1 Validation  1024/1723, done at 2024-02-07 18:19:02, 0:01:29\n",
      "2024-02-07 18:19:01,253 WARNING  pid:20110 util.util:249:enumerateWithEstimate E1 Validation  ----/1723, done at 2024-02-07 18:19:01\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch_ndx in range(1, epochs + 1):\n",
    "\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        epochs,\n",
    "        len(train_dl),\n",
    "        len(val_dl),\n",
    "        batch_size, \n",
    "        (torch.cuda.device_count() if use_cuda else 1),\n",
    "    ))\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "    # logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "    # logMetrics(epoch_ndx, 'val', valMetrics_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 495958])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnMetrics_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
