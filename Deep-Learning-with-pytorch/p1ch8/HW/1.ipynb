{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb5ccf78ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '~/data/data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=5, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # ... <1>\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(8 * 8 * 8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘†\n",
    "\n",
    "æ³¨æ„`padding`, åŠ è¾¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å˜å¤§äº†, lol\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "\n",
    "print(f\"Training on device: {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar2_gpu = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar2\n",
    "]\n",
    "\n",
    "cifar2_val_gpu = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar2_val\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn,\n",
    "                        train_loader, val_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        loss_val = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "                          for p in model.parameters())\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "\n",
    "        for imgs_val, labels_val in val_loader:\n",
    "            imgs_val = imgs_val.to(device=device)\n",
    "            labels_val = labels_val.to(device=device)\n",
    "            outputs_val= model(imgs_val)\n",
    "            loss_val = loss_fn(outputs_val, labels_val)\n",
    "            loss_val += loss_val.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader),\n",
    "                loss_val / len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_gpu = torch.utils.data.DataLoader(cifar2_gpu, batch_size=64, shuffle=True) \n",
    "val_loader_gpu = torch.utils.data.DataLoader(cifar2_val_gpu, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:04:44.100956 Epoch 1, Training loss 0.6045157738551972, Validation loss 0.026439165696501732\n",
      "2024-02-03 15:05:06.040490 Epoch 10, Training loss 0.3217203842037043, Validation loss 0.029808033257722855\n",
      "2024-02-03 15:05:29.643406 Epoch 20, Training loss 0.22612076300154826, Validation loss 0.040951505303382874\n",
      "2024-02-03 15:05:52.589219 Epoch 30, Training loss 0.17968029799355065, Validation loss 0.03860970959067345\n",
      "2024-02-03 15:06:14.296869 Epoch 40, Training loss 0.16121861822665876, Validation loss 0.06223645433783531\n",
      "2024-02-03 15:06:36.534765 Epoch 50, Training loss 0.1680987681363039, Validation loss 0.018849270418286324\n",
      "2024-02-03 15:07:00.352941 Epoch 60, Training loss 0.10739076061613241, Validation loss 0.07567769289016724\n",
      "2024-02-03 15:07:24.547622 Epoch 70, Training loss 0.14430729907219578, Validation loss 0.04462164640426636\n",
      "2024-02-03 15:07:47.818676 Epoch 80, Training loss 0.21990443462399162, Validation loss 0.041996341198682785\n",
      "2024-02-03 15:08:10.858368 Epoch 90, Training loss 0.09105141408694019, Validation loss 0.0652051493525505\n",
      "2024-02-03 15:08:35.146230 Epoch 100, Training loss 0.07521289719897471, Validation loss 0.05264221504330635\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeep(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.90\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ„Ÿè§‰`overfit`, æ¢å•çº¯çš„`resnet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:08:36.696021 Epoch 1, Training loss 0.6956133903211849, Validation loss 0.03914457559585571\n",
      "2024-02-03 15:08:43.330298 Epoch 10, Training loss 0.3681899948864226, Validation loss 0.02247072197496891\n",
      "2024-02-03 15:08:50.632500 Epoch 20, Training loss 0.3312135536199922, Validation loss 0.022993098944425583\n",
      "2024-02-03 15:08:58.566342 Epoch 30, Training loss 0.29430191579518045, Validation loss 0.02033849246799946\n",
      "2024-02-03 15:09:05.694513 Epoch 40, Training loss 0.27118006908589865, Validation loss 0.015692278742790222\n",
      "2024-02-03 15:09:12.877825 Epoch 50, Training loss 0.24556320440617335, Validation loss 0.0163732897490263\n",
      "2024-02-03 15:09:19.822427 Epoch 60, Training loss 0.2307935774705972, Validation loss 0.014913669787347317\n",
      "2024-02-03 15:09:26.735296 Epoch 70, Training loss 0.21132808510854745, Validation loss 0.03199885040521622\n",
      "2024-02-03 15:09:33.657071 Epoch 80, Training loss 0.18891713516727374, Validation loss 0.02573925256729126\n",
      "2024-02-03 15:09:40.736498 Epoch 90, Training loss 0.18314199467563325, Validation loss 0.02091081440448761\n",
      "2024-02-03 15:09:47.817256 Epoch 100, Training loss 0.1666973045297489, Validation loss 0.024543289095163345\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.96\n",
      "Accuracy val: 0.91\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3, 1), padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2) # 16x17\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(3, 1), padding=1)\n",
    "        self.act2 = nn.Tanh() # 16x18\n",
    "        self.pool2 = nn.MaxPool2d(2) # 8x9\n",
    "        self.fc1 = nn.Linear(8 * 9 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:09:48.833813 Epoch 1, Training loss 0.6371667764748737, Validation loss 0.03190235793590546\n",
      "2024-02-03 15:09:55.171506 Epoch 10, Training loss 0.3567518128710947, Validation loss 0.02297438308596611\n",
      "2024-02-03 15:10:02.277135 Epoch 20, Training loss 0.320785586811175, Validation loss 0.028694909065961838\n",
      "2024-02-03 15:10:09.161040 Epoch 30, Training loss 0.296504604778472, Validation loss 0.02401675656437874\n",
      "2024-02-03 15:10:16.492937 Epoch 40, Training loss 0.274524503927322, Validation loss 0.026515578851103783\n",
      "2024-02-03 15:10:23.490752 Epoch 50, Training loss 0.251407992877778, Validation loss 0.03286182880401611\n",
      "2024-02-03 15:10:30.576911 Epoch 60, Training loss 0.22628296446648372, Validation loss 0.030326414853334427\n",
      "2024-02-03 15:10:37.723154 Epoch 70, Training loss 0.20501783642039936, Validation loss 0.024928584694862366\n",
      "2024-02-03 15:10:44.758152 Epoch 80, Training loss 0.1883383798086719, Validation loss 0.03333517909049988\n",
      "2024-02-03 15:10:51.992030 Epoch 90, Training loss 0.18135032959424766, Validation loss 0.037057556211948395\n",
      "2024-02-03 15:10:59.144519 Epoch 100, Training loss 0.16768034352998065, Validation loss 0.050588734447956085\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.87\n",
      "Accuracy val: 0.85\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:11:00.184206 Epoch 1, Training loss 0.6987715762132293, Validation loss 0.03862248733639717\n",
      "2024-02-03 15:11:06.627197 Epoch 10, Training loss 0.36193499899214243, Validation loss 0.01944916322827339\n",
      "2024-02-03 15:11:13.790674 Epoch 20, Training loss 0.31923115433781013, Validation loss 0.015802867710590363\n",
      "2024-02-03 15:11:21.068241 Epoch 30, Training loss 0.2938360104894942, Validation loss 0.0265179593116045\n",
      "2024-02-03 15:11:28.296698 Epoch 40, Training loss 0.2688185013593382, Validation loss 0.014441338367760181\n",
      "2024-02-03 15:11:35.463437 Epoch 50, Training loss 0.2467465505098841, Validation loss 0.01808396726846695\n",
      "Accuracy train: 0.91\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "# æ‡’å¾—è·‘å‰é¢åŽ»è¿è¡Œäº†, æˆ‘ç›´æŽ¥æŠŠä¸€ä¸ªèŽ«æ¨¡åž‹è´´è¿‡æ¥é‡æ–°ç®—\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")\n",
    "\n",
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar2_outside = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar10\n",
    "    if label not in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progression: 0 %\n",
      "progression: 12.5 %\n",
      "progression: 25.0 %\n",
      "progression: 37.5 %\n",
      "progression: 50.0 %\n",
      "progression: 62.5 %\n",
      "progression: 75.0 %\n",
      "progression: 87.5 %\n",
      "progression: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "num_wrong = 0\n",
    "\n",
    "for i, (img, label) in enumerate(cifar2_outside):\n",
    "    if i+1 == 1:\n",
    "        print(\"progression: 0 %\")\n",
    "    elif (i+1) % 5000 == 0:\n",
    "        print(\"progression: {} %\".format((i+1)/len(cifar2_outside) * 100))\n",
    "    img = img.unsqueeze(0).to(device=device)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    prediction = m(model(img))\n",
    "\n",
    "    if prediction[0][0] > 0.95 or prediction[0][1] < 0.05:\n",
    "        # print(i, label, prediction)\n",
    "        num_wrong += 1\n",
    "        prediction_pd = pd.DataFrame([label.cpu().item(), prediction.cpu().detach().numpy()[0]])\n",
    "        prediction_pd.to_csv('prediction.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9570, 0.23925)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_wrong, num_wrong / len(cifar2_outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:12:36.817081 Epoch 1, Training loss 0.6191475906759311, Validation loss 0.032655615359544754\n",
      "2024-02-03 15:12:56.036548 Epoch 10, Training loss 0.3209665701457649, Validation loss 0.019524922594428062\n",
      "2024-02-03 15:13:19.558161 Epoch 20, Training loss 0.232572015968098, Validation loss 0.033993713557720184\n",
      "2024-02-03 15:13:41.533700 Epoch 30, Training loss 0.17312156622576866, Validation loss 0.0372597798705101\n",
      "2024-02-03 15:14:03.832739 Epoch 40, Training loss 0.11123440765840992, Validation loss 0.02317872643470764\n",
      "2024-02-03 15:14:29.066409 Epoch 50, Training loss 0.1279236567058381, Validation loss 0.015563269145786762\n",
      "Accuracy train: 0.99\n",
      "Accuracy val: 0.90\n",
      "None\n",
      "progression: 0 %\n",
      "progression: 12.5 %\n",
      "progression: 25.0 %\n",
      "progression: 37.5 %\n",
      "progression: 50.0 %\n",
      "progression: 62.5 %\n",
      "progression: 75.0 %\n",
      "progression: 87.5 %\n",
      "progression: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "    \n",
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NetResDeep(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")\n",
    "\n",
    "temp = validate(model, train_loader_gpu, val_loader_gpu)\n",
    "\n",
    "print(temp)\n",
    "\n",
    "num_wrong = 0\n",
    "\n",
    "for i, (img, label) in enumerate(cifar2_outside):\n",
    "    if i+1 == 1:\n",
    "        print(\"progression: 0 %\")\n",
    "    elif (i+1) % 5000 == 0:\n",
    "        print(\"progression: {} %\".format((i+1)/len(cifar2_outside) * 100))\n",
    "    img = img.unsqueeze(0).to(device=device)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    prediction = m(model(img))\n",
    "\n",
    "    if prediction[0][0] > 0.95 or prediction[0][1] < 0.05:\n",
    "        # print(i, label, prediction)\n",
    "        num_wrong += 1\n",
    "        prediction_pd = pd.DataFrame([[label.cpu().item(), prediction.cpu().detach().numpy()[0]]])\n",
    "        prediction_pd.to_csv('prediction.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8933, 0.223325)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_wrong, num_wrong / len(cifar2_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (img, label) in enumerate(cifar2_outside):\n",
    "#     outputs = model(img.unsqueeze(0))\n",
    "#     _, predicted = torch.max(outputs, dim=1)\n",
    "#     if predicted != label:\n",
    "#         print(f\"ç¬¬{i}å¼ å›¾ç‰‡è¢«é”™è¯¯åˆ†ç±»ä¸º{class_names[predicted]}, å®žé™…ä¸Šæ˜¯{class_names[label]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
