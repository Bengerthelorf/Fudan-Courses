{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1967774ad0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=5, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # ... <1>\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(8 * 8 * 8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ\n",
    "\n",
    "Ê≥®ÊÑè`padding`, Âä†Ëæπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂèòÂ§ß‰∫Ü, lol\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "\n",
    "print(f\"Training on device: {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar2_gpu = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar2\n",
    "]\n",
    "\n",
    "cifar2_val_gpu = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar2_val\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn,\n",
    "                        train_loader, val_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        loss_val = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "                          for p in model.parameters())\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "\n",
    "        for imgs_val, labels_val in val_loader:\n",
    "            imgs_val = imgs_val.to(device=device)\n",
    "            labels_val = labels_val.to(device=device)\n",
    "            outputs_val= model(imgs_val)\n",
    "            loss_val = loss_fn(outputs_val, labels_val)\n",
    "            loss_val += loss_val.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader),\n",
    "                loss_val / len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_gpu = torch.utils.data.DataLoader(cifar2_gpu, batch_size=64, shuffle=True) \n",
    "val_loader_gpu = torch.utils.data.DataLoader(cifar2_val_gpu, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 10:50:27.277679 Epoch 1, Training loss 0.6104012391749462, Validation loss 0.03489741310477257\n",
      "2024-02-03 10:50:50.351137 Epoch 10, Training loss 0.3131644684987463, Validation loss 0.0203187707811594\n",
      "2024-02-03 10:51:18.850487 Epoch 20, Training loss 0.21637335936924454, Validation loss 0.025120534002780914\n",
      "2024-02-03 10:51:47.144429 Epoch 30, Training loss 0.14033328077405882, Validation loss 0.02068961225450039\n",
      "2024-02-03 10:52:13.026277 Epoch 40, Training loss 0.13399474669224137, Validation loss 0.039109956473112106\n",
      "2024-02-03 10:52:40.384124 Epoch 50, Training loss 0.11893341486241407, Validation loss 0.031134864315390587\n",
      "2024-02-03 10:53:07.490842 Epoch 60, Training loss 0.2603666202467718, Validation loss 0.03549351915717125\n",
      "2024-02-03 10:53:35.664692 Epoch 70, Training loss 0.08294183571057714, Validation loss 0.06914859265089035\n",
      "2024-02-03 10:54:03.030088 Epoch 80, Training loss 0.1255132863476018, Validation loss 0.0520419143140316\n",
      "2024-02-03 10:54:29.204309 Epoch 90, Training loss 0.07455757336252054, Validation loss 0.07196935266256332\n",
      "2024-02-03 10:54:56.266369 Epoch 100, Training loss 0.06995500818749142, Validation loss 0.07524192333221436\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeep(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.91\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÊÑüËßâ`overfit`, Êç¢ÂçïÁ∫ØÁöÑ`resnet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 10:54:58.191926 Epoch 1, Training loss 0.6834989850688132, Validation loss 0.034787606447935104\n",
      "2024-02-03 10:55:05.780613 Epoch 10, Training loss 0.369570419287226, Validation loss 0.022408757358789444\n",
      "2024-02-03 10:55:14.216617 Epoch 20, Training loss 0.32370744190018647, Validation loss 0.027914611622691154\n",
      "2024-02-03 10:55:22.826954 Epoch 30, Training loss 0.2901740530683736, Validation loss 0.021025696769356728\n",
      "2024-02-03 10:55:31.080546 Epoch 40, Training loss 0.268691055144474, Validation loss 0.024957172572612762\n",
      "2024-02-03 10:55:39.185375 Epoch 50, Training loss 0.2500746067921827, Validation loss 0.02278066985309124\n",
      "2024-02-03 10:55:47.060876 Epoch 60, Training loss 0.22987363387824625, Validation loss 0.018666250631213188\n",
      "2024-02-03 10:55:54.617541 Epoch 70, Training loss 0.21082317757948188, Validation loss 0.023035326972603798\n",
      "2024-02-03 10:56:02.990660 Epoch 80, Training loss 0.19486768130853677, Validation loss 0.016683857887983322\n",
      "2024-02-03 10:56:11.999562 Epoch 90, Training loss 0.17915334334229208, Validation loss 0.024944255128502846\n",
      "2024-02-03 10:56:19.632734 Epoch 100, Training loss 0.16163094417684398, Validation loss 0.014823900535702705\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.96\n",
      "Accuracy val: 0.90\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3, 1), padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2) # 16x17\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(3, 1), padding=1)\n",
    "        self.act2 = nn.Tanh() # 16x18\n",
    "        self.pool2 = nn.MaxPool2d(2) # 8x9\n",
    "        self.fc1 = nn.Linear(8 * 9 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 10:58:51.023968 Epoch 1, Training loss 0.6668332179260862, Validation loss 0.035441283136606216\n",
      "2024-02-03 10:58:57.827627 Epoch 10, Training loss 0.3652876191268301, Validation loss 0.019229363650083542\n",
      "2024-02-03 10:59:05.291140 Epoch 20, Training loss 0.3238427865846901, Validation loss 0.01762267015874386\n",
      "2024-02-03 10:59:12.925929 Epoch 30, Training loss 0.29261245469378816, Validation loss 0.02179892174899578\n",
      "2024-02-03 10:59:20.876394 Epoch 40, Training loss 0.2734147717428815, Validation loss 0.016872115433216095\n",
      "2024-02-03 10:59:28.749108 Epoch 50, Training loss 0.2448071079554072, Validation loss 0.0215920340269804\n",
      "2024-02-03 10:59:36.440292 Epoch 60, Training loss 0.2256851297370188, Validation loss 0.020621882751584053\n",
      "2024-02-03 10:59:44.318465 Epoch 70, Training loss 0.20925082157182087, Validation loss 0.0212523452937603\n",
      "2024-02-03 10:59:52.016799 Epoch 80, Training loss 0.18875115753928567, Validation loss 0.019672119989991188\n",
      "2024-02-03 10:59:59.143626 Epoch 90, Training loss 0.1763209862409124, Validation loss 0.03367076814174652\n",
      "2024-02-03 11:00:06.188807 Epoch 100, Training loss 0.16772536980878017, Validation loss 0.02649548277258873\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.96\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 11:43:10.695515 Epoch 1, Training loss 0.6379847699289869, Validation loss 0.0316740944981575\n",
      "2024-02-03 11:43:17.135070 Epoch 10, Training loss 0.3563068223417185, Validation loss 0.025845563039183617\n",
      "2024-02-03 11:43:25.129758 Epoch 20, Training loss 0.31497339780922906, Validation loss 0.019146736711263657\n",
      "2024-02-03 11:43:32.634904 Epoch 30, Training loss 0.29031328173579685, Validation loss 0.019030680879950523\n",
      "2024-02-03 11:43:40.559151 Epoch 40, Training loss 0.2704985573603089, Validation loss 0.02380673959851265\n",
      "2024-02-03 11:43:48.335279 Epoch 50, Training loss 0.24516844198961926, Validation loss 0.012765792198479176\n",
      "Accuracy train: 0.92\n",
      "Accuracy val: 0.90\n"
     ]
    }
   ],
   "source": [
    "# ÊáíÂæóË∑ëÂâçÈù¢ÂéªËøêË°å‰∫Ü, ÊàëÁõ¥Êé•Êää‰∏Ä‰∏™Ëé´Ê®°ÂûãË¥¥ËøáÊù•ÈáçÊñ∞ÁÆó\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")\n",
    "\n",
    "temp = validate(model, train_loader_gpu, val_loader_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar2_outside = [(\n",
    "    img.to(device=device),\n",
    "    torch.tensor(label).to(device=device)\n",
    "    )\n",
    "    for img, label in cifar10\n",
    "    if label not in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progression: 0 %\n",
      "progression: 12.5 %\n",
      "progression: 25.0 %\n",
      "progression: 37.5 %\n",
      "progression: 50.0 %\n",
      "progression: 62.5 %\n",
      "progression: 75.0 %\n",
      "progression: 87.5 %\n",
      "progression: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "num_wrong = 0\n",
    "\n",
    "for i, (img, label) in enumerate(cifar2_outside):\n",
    "    if i+1 == 1:\n",
    "        print(\"progression: 0 %\")\n",
    "    elif (i+1) % 5000 == 0:\n",
    "        print(\"progression: {} %\".format((i+1)/len(cifar2_outside) * 100))\n",
    "    img = img.unsqueeze(0).to(device=device)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    prediction = m(model(img))\n",
    "\n",
    "    if prediction[0][0] > 0.95 or prediction[0][1] < 0.05:\n",
    "        # print(i, label, prediction)\n",
    "        num_wrong += 1\n",
    "        prediction_pd = pd.DataFrame([[label.cpu().item(), prediction.cpu().detach().numpy()[0]]], columns=['label', 'prediction'])\n",
    "        prediction_pd.to_csv('prediction.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6574, 0.16435)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_wrong, num_wrong / len(cifar2_outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-03 11:56:09.179214 Epoch 1, Training loss 0.6051068778630275, Validation loss 0.02200504019856453\n",
      "2024-02-03 11:56:30.712786 Epoch 10, Training loss 0.32701538920782175, Validation loss 0.015018164180219173\n",
      "2024-02-03 11:56:54.747690 Epoch 20, Training loss 0.23317246433276279, Validation loss 0.029492247849702835\n",
      "2024-02-03 11:57:18.833585 Epoch 30, Training loss 0.1877649053456677, Validation loss 0.02070627547800541\n",
      "2024-02-03 11:57:43.054405 Epoch 40, Training loss 0.11485524988098508, Validation loss 0.02831980399787426\n",
      "2024-02-03 11:58:09.394786 Epoch 50, Training loss 0.08638301159545875, Validation loss 0.039085838943719864\n",
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.91\n",
      "None\n",
      "progression: 0 %\n",
      "progression: 12.5 %\n",
      "progression: 25.0 %\n",
      "progression: 37.5 %\n",
      "progression: 50.0 %\n",
      "progression: 62.5 %\n",
      "progression: 75.0 %\n",
      "progression: 87.5 %\n",
      "progression: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "    \n",
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NetResDeep(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader_gpu,\n",
    "    val_loader = val_loader_gpu\n",
    ")\n",
    "\n",
    "temp = validate(model, train_loader_gpu, val_loader_gpu)\n",
    "\n",
    "print(temp)\n",
    "\n",
    "num_wrong = 0\n",
    "\n",
    "for i, (img, label) in enumerate(cifar2_outside):\n",
    "    if i+1 == 1:\n",
    "        print(\"progression: 0 %\")\n",
    "    elif (i+1) % 5000 == 0:\n",
    "        print(\"progression: {} %\".format((i+1)/len(cifar2_outside) * 100))\n",
    "    img = img.unsqueeze(0).to(device=device)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    prediction = m(model(img))\n",
    "\n",
    "    if prediction[0][0] > 0.95 or prediction[0][1] < 0.05:\n",
    "        # print(i, label, prediction)\n",
    "        num_wrong += 1\n",
    "        prediction_pd = pd.DataFrame([[label.cpu().item(), prediction.cpu().detach().numpy()[0]]])\n",
    "        prediction_pd.to_csv('prediction.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11042, 0.27605)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_wrong, num_wrong / len(cifar2_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (img, label) in enumerate(cifar2_outside):\n",
    "#     outputs = model(img.unsqueeze(0))\n",
    "#     _, predicted = torch.max(outputs, dim=1)\n",
    "#     if predicted != label:\n",
    "#         print(f\"Á¨¨{i}Âº†ÂõæÁâáË¢´ÈîôËØØÂàÜÁ±ª‰∏∫{class_names[predicted]}, ÂÆûÈôÖ‰∏äÊòØ{class_names[label]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
