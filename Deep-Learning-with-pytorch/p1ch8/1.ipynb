{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4529134590>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "为什么一定要换成`list`, 直接`dataset`不好吗?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "numel_list = [p.numel()\n",
    "              for p in connected_model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是:\n",
    "\n",
    "$$\n",
    "[3072 \\times 1024, 1024 \\times 512, 512 \\times 128, 128 \\times 2, 1024, 512, 128, 2]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))\n",
    "\n",
    "numel_list = [p.numel() for p in first_model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "这两段说明参数很多, LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3) # <1>\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 `cpu()` 方法并不会改变原始张量的设备。它会返回一个新的张量，这个新张量在CPU上，而原始张量的设备不变。\n",
    "\n",
    "所以，如果你在调用 `img.cpu()` 后再次调用 `img`，`img` 仍然在原来的设备上（在你的例子中，应该是CUDA设备）。\n",
    "\n",
    "如果你想改变 `img` 的设备，你需要将 `cpu()` 的结果赋值给 `img`，如下所示：\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "这样，`img` 就会在CPU上了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层，这是在卷积神经网络（Convolutional Neural Networks，CNN）中常用的一种层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层，这是在卷积神经网络（Convolutional Neural Networks，CNN）中常用的一种层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层，这是在卷积神经网络（Convolutional Neural Networks，CNN）中常用的一种层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层，这是在卷积神经网络（Convolutional Neural Networks，CNN）中常用的一种层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码创建了一个二维卷积层，这是在卷积神经网络（Convolutional Neural Networks，CNN）中常用的一种层。\n",
    "\n",
    "`nn.Conv2d(3, 16, kernel_size=3)` 这行代码的参数解释如下：\n",
    "\n",
    "- `3` 是输入的通道数。在这个例子中，它是3，这意味着输入是一个彩色图像（红、绿、蓝三个通道）。\n",
    "- `16` 是输出的通道数。这意味着这个卷积层将生成16个特征图（feature maps）。\n",
    "- `kernel_size=3` 指定了卷积核的大小。在这个例子中，卷积核的大小是3x3。\n",
    "\n",
    "输出 `Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))` 是这个卷积层的字符串表示。它告诉我们这个卷积层的一些参数：\n",
    "\n",
    "- `3` 是输入的通道数。\n",
    "- `16` 是输出的通道数。\n",
    "- `kernel_size=(3, 3)` 是卷积核的大小。\n",
    "- `stride=(1, 1)` 是卷积的步长。步长是卷积核在输入特征图上移动的步数。在这个例子中，步长是1，这意味着卷积核在水平和垂直方向上每次移动一步。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
