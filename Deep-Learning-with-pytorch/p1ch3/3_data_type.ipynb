{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.float32 or torch.float: 32-bit floating-point\n",
    "- torch.float64 or torch.double: 64-bit, double-precision floating-point\n",
    "- torch.float16 or torch.half: 16-bit, half-precision floating-point\n",
    "- torch.int8: signed 8-bit integers\n",
    "- torch.uint8: unsigned 8-bit integers\n",
    "- torch.int16 or torch.short: signed 16-bit integers\n",
    "- torch.int32 or torch.int: signed 32-bit integers\n",
    "- torch.int64 or torch.long: signed 64-bit integers\n",
    "- torch.bool: Boolean\n",
    "\n",
    "> 数据类型与内存占用直接相关. 用int32会爆内存的换成uint8等可能就可以正常运行了."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]], dtype=torch.float64),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]], dtype=torch.int16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.int16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points.dtype, short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3774, 0.0838, 0.6831, 0.8665, 0.0912], dtype=torch.float64)\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.short()\n",
    "print(points_64)\n",
    "print(points_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "`.short()` 并没有取四舍五入, 而是直接取其整数部分.\n",
    "\n",
    "```python\n",
    ">>> torch.tensor([12.3]).short()\n",
    "tensor([12], dtype=torch.int16)\n",
    ">>> torch.tensor([12.7]).short()\n",
    "tensor([12], dtype=torch.int16)\n",
    "```\n",
    "\n",
    "相当于 numpy 中的 `np.floor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "其存放是按照 `torch.float64` 来存放的, 也就是按照内存占用最大的来存放的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
