{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files' IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "points = torch.ones(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†™æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, '../data/p1ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¨ python çš„æ¨¡å¼\n",
    "\n",
    "with open('../data/p1ch3/ourpoints.t', 'wb') as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘†\n",
    "\n",
    "`open` å‡½æ•°ä¸­çš„ `wb` å‚æ•°è¡¨ç¤ºä»¥äºŒè¿›åˆ¶å†™å…¥çš„æ–¹å¼æ‰“å¼€æ–‡ä»¶\n",
    "\n",
    "| Mode |\tDescription |\n",
    "| --- | --- |\n",
    "| `r` |\tOpen a file for reading. (default) |\n",
    "| `w` |\tOpen a file for writing. Creates a new file if it does not exist or truncates the file if it exists. |\n",
    "| `x` |\tOpen a file for exclusive creation. If the file already exists, the operation fails. |\n",
    "| `a` |\tOpen for appending at the end of the file without truncating it. Creates a new file if it does not exist. |\n",
    "| `t` |\tOpen in text mode. (default) |\n",
    "| `b` |\tOpen in binary mode. |\n",
    "| `+` |\tOpen a file for updating (reading and writing) |\n",
    "\n",
    "ä¸­æ–‡ ğŸ‘‡\n",
    "\n",
    "| æ¨¡å¼ |\tæè¿° |\n",
    "| --- | --- |\n",
    "| `r` |\tæ‰“å¼€ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œè¯»å–ã€‚ï¼ˆé»˜è®¤ï¼‰ |\n",
    "| `w` |\tæ‰“å¼€ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œå†™å…¥ã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶å­˜åœ¨åˆ™æ¸…ç©ºæ–‡ä»¶ã€‚ |\n",
    "| `x` |\tç‹¬å æ–¹å¼åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ã€‚å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™æ“ä½œå¤±è´¥ã€‚ |\n",
    "| `a` |\tåœ¨æ–‡ä»¶æœ«å°¾è¿½åŠ å†…å®¹ï¼Œä¸ä¼šæ¸…ç©ºæ–‡ä»¶ã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°æ–‡ä»¶ã€‚ |\n",
    "| `t` |\tä»¥æ–‡æœ¬æ¨¡å¼æ‰“å¼€ã€‚ï¼ˆé»˜è®¤ï¼‰ |\n",
    "| `b` |\tä»¥äºŒè¿›åˆ¶æ¨¡å¼æ‰“å¼€ã€‚ |\n",
    "| `+` |\tæ‰“å¼€ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œæ›´æ–°ï¼ˆè¯»å–å’Œå†™å…¥ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯»æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('../data/p1ch3/ourpoints.t')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/p1ch3/ourpoints.t', 'rb') as f:\n",
    "    a = torch.load(f)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'w')\n",
    "dset = f.create_dataset('coords', data = points.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘†\n",
    "\n",
    "è¿™æ®µä»£ç æ˜¯ä½¿ç”¨h5pyåº“æ¥åˆ›å»ºä¸€ä¸ªHDF5æ–‡ä»¶ï¼Œå¹¶åœ¨å…¶ä¸­å­˜å‚¨æ•°æ®ã€‚\n",
    "\n",
    "å…·ä½“æ¥è¯´ï¼š\n",
    "\n",
    "1. `f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'w')`ï¼šè¿™è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªHDF5æ–‡ä»¶ï¼Œæ–‡ä»¶è·¯å¾„æ˜¯'../data/p1ch3/ourpoints.hdf5'ï¼Œå¹¶ä¸”ä»¥å†™å…¥æ¨¡å¼ï¼ˆ'w'ï¼‰æ‰“å¼€è¿™ä¸ªæ–‡ä»¶ã€‚å¦‚æœæ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œå®ƒå°†è¢«æ¸…ç©ºï¼›å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ã€‚\n",
    "\n",
    "2. `dset = f.create_dataset('coords', data = points.numpy())`ï¼šè¿™è¡Œä»£ç åœ¨HDF5æ–‡ä»¶ä¸­åˆ›å»ºäº†ä¸€ä¸ªåä¸º'coords'çš„æ•°æ®é›†ï¼Œå¹¶å°†`points.numpy()`çš„æ•°æ®å­˜å‚¨åœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ã€‚`points.numpy()`æ˜¯å°†PyTorchå¼ é‡è½¬æ¢ä¸ºNumPyæ•°ç»„ã€‚\n",
    "\n",
    "3. `f.close()`ï¼šè¿™è¡Œä»£ç å…³é—­äº†HDF5æ–‡ä»¶ã€‚åœ¨å®Œæˆæ‰€æœ‰çš„è¯»å†™æ“ä½œåï¼Œåº”è¯¥å…³é—­æ–‡ä»¶ä»¥é‡Šæ”¾ç³»ç»Ÿèµ„æºã€‚\n",
    "\n",
    "HDF5æ˜¯ä¸€ç§å­˜å‚¨å¤§è§„æ¨¡ç§‘å­¦æ•°ç»„æ•°æ®çš„æ–‡ä»¶æ ¼å¼ï¼Œå®ƒå¯ä»¥è®©ä½ å­˜å‚¨å¤§é‡çš„æ•°å€¼æ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥é«˜æ•ˆåœ°è¢«Pythonæˆ–å…¶ä»–è¯­è¨€çš„ç¨‹åºè¯»å–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"coords\": shape (3, 4), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'r')\n",
    "dset = f['coords']\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_points = dset[:]\n",
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç”±ä¸Šå¯è§æ˜¯numpy.arrayçš„å½¢å¼, è½¬æˆtensor\n",
    "\n",
    "last_points = torch.from_numpy(dset[:])\n",
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¹Ÿå¯ä»¥\n",
    "last_points = torch.tensor(dset[:])\n",
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘†\n",
    "\n",
    "æ³¨æ„è¦å°†å…¶å…³é—­, ä»¥é‡Šæ”¾ç³»ç»Ÿèµ„æº."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ‰“å¼€æ–‡ä»¶åœ¨ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m4.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], [\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]])\n\u001b[1;32m      2\u001b[0m points_gpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m4.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], [\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpoints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpoints_gpu\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
    "points + points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = points.cuda()\n",
    "points + points_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
