{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. About memory storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0],\n",
    "                       [5.0, 3.0],\n",
    "                       [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "PyTorch 在其最新版本中已经弃用了 `TypedStorage` 类，而只保留了 `UntypedStorage` 类。`TypedStorage` 类是一个旧的类，它允许你创建一个特定类型的存储，如 `FloatStorage` 或 `LongStorage`。然而，PyTorch 的开发者决定弃用这个类，因为它增加了代码的复杂性，而且在大多数情况下并不需要。\n",
    "\n",
    "所以会有:\n",
    "\n",
    "```bash\n",
    "/tmp/ipykernel_24202/484287676.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
    "  points.storage()\n",
    "```\n",
    "\n",
    "的提示\n",
    "\n",
    "值得注意的是, 如果将其改换成 `points.untyped_storage()` 时输出和原输出远不一样:\n",
    "\n",
    "```bash\n",
    " 0\n",
    " 0\n",
    " 128\n",
    " 64\n",
    " 0\n",
    " 0\n",
    " 128\n",
    " 63\n",
    " 0\n",
    " 0\n",
    " 160\n",
    " 64\n",
    " 0\n",
    " 0\n",
    " 64\n",
    " 64\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 64\n",
    " 0\n",
    " 0\n",
    " 128\n",
    " 63\n",
    "[torch.storage.UntypedStorage(device=cpu) of size 24]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1] # 这是将points的第二行赋值给second_point, 即[5.0, 3.0]\n",
    "second_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "`second_point.storage_offset()` 返回的 `2` 是指存储中的第三个元素, 即:\n",
    "\n",
    "```bash\n",
    " 4.0\n",
    " 1.0\n",
    " 5.0\n",
    " 3.0\n",
    " 2.0\n",
    " 1.0\n",
    "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
    "```\n",
    "\n",
    "中的 `5.0`, 即第 `2` 个数开始. \n",
    "\n",
    "同理的, 如果是:\n",
    "\n",
    "```python\n",
    ">>> first_point = points[0]\n",
    ">>> first_point.storage_offset()\n",
    "```\n",
    "\n",
    "则会返回 `0`. 对应 `4.0`, 即第 `0` 个数开始."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size(), second_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "这二者是可以互换的, 区别在于 `.size()` 是一个方法, 而 `.shape` 是一个属性."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_point[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  3.]),\n",
       " tensor([[ 4.,  1.],\n",
       "         [10.,  3.],\n",
       "         [ 2.,  1.]]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point, points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "对此, 我们可以看到: 对于 `second_point` 的修改, 会影响到 `points` 中的值. 也就是说 `second_point` 和 `points` 共享了同一个存储空间.\n",
    "\n",
    "---\n",
    "\n",
    "由此, 对于数据的复制不能简单用 `=` 来赋值, 而是要用 `.clone()` 方法来进行复制.\n",
    "\n",
    "👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  3.]),\n",
       " tensor([[ 4.,  1.],\n",
       "         [10.,  3.],\n",
       "         [ 2.,  1.]]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_point = points[1].clone()\n",
    "\n",
    "another_point, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_point.storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "其返回为 `0`, 而不是 `2`, 侧面说明了 `another_point` 不再是和 `points` 共享一块内存空间, 而是新开辟了一块."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (2, 1))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "second_point.stride(), points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "`stride()`, 顾名思义, 就是步长. 也就是说, 从一个元素到下一个元素, 需要跳过多少个元素.\n",
    "\n",
    "对于 `points` 来说, 由于其是一个 `2 * 1` 的矩阵, 而 `stride()` 的方法是同一维度下来说的, 也就是, 当列上的元素需要跳到下一个维度的时候, 需要跳过 `2` 个元素\n",
    "\n",
    "```\n",
    "→ [ 4.,  1.],\n",
    "→ [10.,  3.],\n",
    "  [ 2.,  1.]\n",
    "```\n",
    "\n",
    "而从列的维度上来说时, 则只需要跳过 `1` 个元素\n",
    "\n",
    "```\n",
    "  ⬇    ⬇\n",
    "[ 4.,  1.],\n",
    "[10.,  3.],\n",
    "[ 2.,  1.]\n",
    "```\n",
    "\n",
    "同理的, 对于 `secon_point` 来说, 对于其只有一个维度, 那么其 `stride()` 的值就是 `1`.\n",
    "\n",
    "```\n",
    "  ⬇    ⬇\n",
    "[10.,  3.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 10.,  2.],\n",
       "        [ 1.,  3.,  1.]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转置\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是, 值得注意的是, 这个 `.t()` 方法并内有进行内存的拷贝, 其内存的 `id`仍是一样的, 也就是说, 他们共享了同一块内存空间.\n",
    "\n",
    "👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于更高维的矩阵的 `stride()`: \n",
    "\n",
    "👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "也就是, 我们可以这样计算: stride就是, 本元素的下面的元素相乘之和.\n",
    "\n",
    "$$\n",
    "tensor = (x_1, x_2 \\cdots x_{n-1}, x_n) \\\\\n",
    "\\begin{aligned}\n",
    "\\text{strid} _{1} &= x_2 \\times x_3 \\cdots x_n \\\\\n",
    "\\text{strid} _{2} &= x_3 \\times x_4 \\cdots x_n \\\\\n",
    "& \\vdots \\\\\n",
    "\\text{strid} _{n-1} &= x_n \\\\\n",
    "\\text{strid} _{n} &= 1\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t_t = some_t.transpose(0, 2)\n",
    "# 值得注意的是:\n",
    "# transpose() 需要的矩阵是 <= 2 维的, 所以对于更高维的矩阵的转置, 需要指定某两个维度\n",
    "# 且 t() 和 transpose() 是不一样的, t() 是严格的二维转换, 而 transpose() 可以处理任意维度, 通过指定两个维度\n",
    "some_t_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆\n",
    "\n",
    "不理解, 等之后再看."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "points.is_contiguous()\n",
    "points_t.is_contiguous()\n",
    "```\n",
    "\n",
    "其中第一个是 `ture`, 第二个是 `false`, 也就是说, `point` 连续而 `points_t` 不连续.\n",
    "\n",
    "理解就是对于内存中存的数据:\n",
    "\n",
    "```bash\n",
    " 4.0\n",
    " 1.0\n",
    " 5.0\n",
    " 3.0\n",
    " 2.0\n",
    " 1.0\n",
    "```\n",
    "\n",
    "来说, `point` 可以按顺序一路读下去, 而 `points_t` 则需要反复横跳."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
